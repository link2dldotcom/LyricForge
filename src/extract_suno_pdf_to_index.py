# extract_suno_pdf_to_index.py

from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.schema import Document
from pdfminer.high_level import extract_text
import os

# è¾“å…¥ PDF è·¯å¾„
pdf_path = "src/sunoKnowledge2.pdf"  # æ›¿æ¢ä¸ºä½ çš„ PDF æ–‡ä»¶è·¯å¾„

# 1. æå– PDF æ–‡æœ¬
print("ğŸ“– æ­£åœ¨æå– PDF æ–‡æœ¬...")
full_text = extract_text(pdf_path)

# 2. åˆ†æ®µå¤„ç†ï¼ˆä»¥æ¢è¡Œæˆ–ç©ºè¡Œä¸ºæ®µè½ï¼‰
paragraphs = [p.strip() for p in full_text.split("\n\n") if len(p.strip()) > 40]
print(f"âœ… æå–æ®µè½æ•°ï¼š{len(paragraphs)}")

# 3. è½¬æ¢ä¸º Document åˆ—è¡¨
docs = [Document(page_content=p, metadata={"source": "suno_pdf"}) for p in paragraphs]

# 4. å‘é‡åµŒå…¥æ¨¡å‹
print("ğŸ” æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹...")
embedding_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")

# 5. æ„å»ºå¹¶ä¿å­˜ FAISS å‘é‡åº“
print("ğŸ§  æ­£åœ¨æ„å»ºçŸ¥è¯†å‘é‡ç´¢å¼•...")
vectorstore = FAISS.from_documents(docs, embedding_model)
os.makedirs("faiss_index_knowledge", exist_ok=True)
vectorstore.save_local("faiss_index_knowledge")

print("ğŸ‰ çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œå·²ä¿å­˜è‡³ faiss_index_knowledge/")
